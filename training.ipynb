{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMmqpHMK83ds9x8/4dRngbr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giutassarotti/IAesame/blob/main/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKHD7OMRte64"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgnirP7MuB-C"
      },
      "source": [
        "#**Definizione delle funzioni per il caricamento del Dataset**#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNxwdbXeuJk3"
      },
      "source": [
        "import pandas\n",
        "\n",
        "def io_load_multiple_csv(csv_path_list):\n",
        "  dataframe_list = []\n",
        "  for elem in csv_path_list:\n",
        "    dataframe_list.append(io_load_csv(elem))\n",
        "  return dataframe_list\n",
        "\n",
        "def io_load_csv(csv_path):\n",
        "  return pandas.read_csv(csv_path)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy6IygiVv2Nj"
      },
      "source": [
        "# **Definizione delle funzioni per trattare il Dataset** #\n",
        "\n",
        "È fondamentale riconoscere quali colonne siano numeriche e quali categoriche per il trattamento dei dati."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJXOCwf6wqmc"
      },
      "source": [
        "import matplotlib.pyplot as pyplot\n",
        "import seaborn\n",
        "\n",
        "def is_categorical(elem):\n",
        "  return type(elem) is str\n",
        "\n",
        "def is_numeric(elem):\n",
        "  return not is_categorical(elem)\n",
        "\n",
        "def get_numeric_features(dataframe):\n",
        "  numeric_features = []\n",
        "  for elem in dataframe:\n",
        "    if is_numeric(dataframe[elem][0]):\n",
        "      numeric_features.append(elem)\n",
        "  return numeric_features\n",
        "\n",
        "def get_categorical_features(dataframe):\n",
        "  categorical_features = []\n",
        "  for elem in dataframe:\n",
        "    if is_categorical(dataframe[elem][0]):\n",
        "      categorical_features.append(elem)\n",
        "  return categorical_features"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blZbOgqklvwk"
      },
      "source": [
        "#**Definizioni delle funzioni per l'Analisi del Dataset**#\n",
        "\n",
        "Sono definite qui le funzioni per la stampa dei grafici relativi alla feature ricercata e per la stampa di informazioni generali sul Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7RKn_JOmAXh"
      },
      "source": [
        "def print_feature_plots(dataframe, feature_target):\n",
        "  categorical_features = get_categorical_features(dataframe)\n",
        "  numeric_features = get_numeric_features(dataframe)\n",
        "  for elem in dataframe:\n",
        "    if elem == feature_target:\n",
        "      continue\n",
        "    if elem in categorical_features:\n",
        "      plot = seaborn.catplot(x = feature_target, \n",
        "                        col = elem, \n",
        "                        data = dataframe, \n",
        "                        kind = 'count')\n",
        "    elif elem in numeric_features:\n",
        "      plot = seaborn.displot(data = dataframe,\n",
        "                        x = elem,\n",
        "                        hue = feature_target) \n",
        "  \n",
        "    pyplot.show()\n",
        "\n",
        "def print_infos(dataframe):\n",
        "  print(\"Informazioni del Dataframe:\\n\")\n",
        "  print(\"Righe     : {}\".format(dataframe.shape[0]) )\n",
        "  print(\"Colonne  : {}\".format(dataframe.shape[1]))\n",
        "  print(\"\\nFeatures :\\n{}\".format(dataframe.columns.tolist()))\n",
        "  print(\"\\nValori Unici :\\n{}\".format(dataframe.nunique()))\n",
        "\n",
        "  print(\"\\nInformazioni del Dataframe:\")\n",
        "  dataframe.info()"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy2x3f3Yw48b"
      },
      "source": [
        "# **Definizioni delle funzioni per il Modello** #\n",
        "\n",
        "Vengono qui definite le funzioni per la creazione e l'utilizzo del modello.\n",
        "È stato scelto di sfruttare la libreria Scikit-learn (in breve sklearn) per definire la Pipeline e l'algoritmo di classificazione.\n",
        "\n",
        "Come classificatore è stato scelto l'algoritmo di Random Forest, che è un algoritmo di apprendimento supervisionato di tipo Ensemble, ossia una tecnica che combina le previsioni di più algoritmi di apprendimento per fare previsioni più accurate. \n",
        "\n",
        "Nello specifico, utilizza il Bootstrap Aggregation (Bagging in breve) come metodo di Ensemble e il Decision Tree come modello individuale, ossia combina molti alberi decisionali in un unico modello.\n",
        "\n",
        "Il risultato finale restituito dal Random Forest altro non è che la maggioranza della classe risultante dei diversi Decision Tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kCmvT9Gw-re"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "def create_preprocessor(dataframe):\n",
        "  numeric_features = get_numeric_features(dataframe)\n",
        "  numeric_transformer = Pipeline(\n",
        "      steps = [('imputer', SimpleImputer(strategy='median')),\n",
        "               ('scaler', StandardScaler())])\n",
        "\n",
        "  categorical_features = get_categorical_features(dataframe)\n",
        "  categorical_transformer = Pipeline(\n",
        "      steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "             ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "  return ColumnTransformer(\n",
        "      transformers=[('num', numeric_transformer, numeric_features),\n",
        "                    ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "def create_model(dataframe):\n",
        "  preprocessor = create_preprocessor(dataframe)\n",
        "\n",
        "  return Pipeline(\n",
        "      steps = [('preprocessor', preprocessor),\n",
        "               ('classifier', RandomForestClassifier())])\n",
        "  \n",
        "def train_model(model, dataframe_train, dataframe_train_target):\n",
        "  model.fit(dataframe_train, dataframe_train_target)\n",
        "  print('Training score: {}'.format(model.score(dataframe_train, dataframe_train_target)))\n",
        "  return model\n",
        "\n",
        "def print_test_model(model, dataframe_test, dataframe_test_target):\n",
        "  preds = model.predict(dataframe_test)\n",
        "  print('Test score: {}'.format(model.score(dataframe_test, dataframe_test_target)))\n",
        "  print(classification_report(dataframe_test_target, preds, target_names= ['Usciti', 'Rimasti']))\n",
        "\n",
        "def print_accuracy(model, dataframe_test, dataframe_test_target):\n",
        "  preds = model.predict(dataframe_test)\n",
        "  print('Accuratezza:')\n",
        "  print(accuracy_score(dataframe_test_target, preds))"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYIgJQKpxtz9"
      },
      "source": [
        "# **Caricamento del Dataset** #\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L14JX0xxs6V"
      },
      "source": [
        "dataframe_train_path = \"train.csv\"\n",
        "dataframe_test_path = \"test.csv\"\n",
        "\n",
        "dataframe_train, dataframe_test = io_load_multiple_csv([dataframe_train_path, dataframe_test_path])"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFQzJStpingK"
      },
      "source": [
        "# **Analisi del Dataset** #\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DguGiX55oRaH"
      },
      "source": [
        "**Stampa preliminare delle prime 5 righe del Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyVCGOWmofQR"
      },
      "source": [
        "dataframe_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCmeyGcuolQp"
      },
      "source": [
        "È necessario l'utilizzo di stampe per valutare manualmente:\n",
        "\n",
        "*   Presenza di valori indesiderati nel Dataset, quali elementi vuoti o di tipo sbagliato all'interno, che altrimenti altererebbero il riconoscimento della tipologia di colonna (Numerale o Categorico) o creerebbero altri problemi.\n",
        "*   Presenza di colonne indesiderate, quali ad esempio colonne di valori ID o di altre informazioni totalmente inutili o dannose per l'algoritmo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlOswq5roACV"
      },
      "source": [
        "**Filtraggio dei valori**\n",
        "\n",
        "Viene qui di seguito eseguita una stampa dell'analisi delle colonne, dove è possibile notare che nessuna colonna presenta righe con valori nulli o sbagliati. Questa parte non necessita quindi accorgimenti.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR8eVQ3notOq"
      },
      "source": [
        "print_infos(dataframe_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-a3deGRoaQ_"
      },
      "source": [
        "**Filtraggio delle colonne irrilevanti**\n",
        "\n",
        "Vengono qui creati e stampati grafici che prendono come ascissa sempre la feature \"Exited\", ossia mettono a confronto ogni altra feature con la feature che ci interessa prevedere.\n",
        "\n",
        "Verranno inizialmente escluse le colonne inutili per la correlazione con la feature \"Exited\", ossia di natura completamente casuale rispetto al fatto che l'utente sia uscito o meno dalla banca:\n",
        "\n",
        "*   CustomerId\n",
        "*   RowNumber\n",
        "*   Surname\n",
        "\n",
        "Successivamente, avviando la stampa dei grafici, è possibile considerare la possibilità di ignorare una feature perchè visivamente poco rilevante per l'algoritmo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4OqjErJpClu"
      },
      "source": [
        "dataframe_train.pop(\"CustomerId\")\n",
        "dataframe_train.pop(\"Surname\")\n",
        "dataframe_train.pop(\"RowNumber\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDH55U4JpEJQ"
      },
      "source": [
        "feature_target = \"Exited\"\n",
        "print_feature_plots(dataframe_train, feature_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBTmOHDFxCXs"
      },
      "source": [
        "#**Esecuzione**#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq5qSldxVTub"
      },
      "source": [
        "####**Preparazione**####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHU4buHwVgRH"
      },
      "source": [
        "le = LabelEncoder()\n",
        "\n",
        "dataframe_train_target = le.fit_transform(dataframe_train.pop(feature_target))\n",
        "dataframe_test_target = le.transform(dataframe_test.pop(feature_target))"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzR-eMxYWUZ9"
      },
      "source": [
        "####**Classificatore**####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1kv3OJKWiTn"
      },
      "source": [
        "dataframe_train = dataframe_train.drop_duplicates()\n",
        "\n",
        "classifier = create_model(dataframe_train)\n",
        "\n",
        "classifier = train_model(classifier, dataframe_train, dataframe_train_target)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV8F-pbY0aqi"
      },
      "source": [
        "**Stampa Totale dei risultati**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJDKet4s0Wf6",
        "outputId": "3232c022-caf5-42b3-fdf2-c320e58f064c"
      },
      "source": [
        "print_test_model(classifier, dataframe_test, dataframe_test_target)"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.85375\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Usciti       0.86      0.97      0.91      1255\n",
            "     Rimasti       0.79      0.44      0.57       345\n",
            "\n",
            "    accuracy                           0.85      1600\n",
            "   macro avg       0.83      0.70      0.74      1600\n",
            "weighted avg       0.85      0.85      0.84      1600\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjKGo-HE0fqx"
      },
      "source": [
        "**Stampa dell'accuratezza**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TDzc52s0WUV",
        "outputId": "64b2fc51-0819-4df9-b2d1-8ce23e6ca4a4"
      },
      "source": [
        "print_accuracy(classifier, dataframe_test, dataframe_test_target)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuratezza:\n",
            "0.85375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}